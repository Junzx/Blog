# 目录
- 决策树、bagging、boosting、adaboost
- 手推逻辑回归
- k-means的k选择、二分k-means
- PCA与word embedding
- SVM
- SVD与推荐

---

### 线性模型

- 基于均方误差最小化进行模型求解的方法成为“最小二乘法”，在线性回归中，最小二乘法就是找到一条直线，使所有样本到直线上的欧氏距离之和最小。
- LDA：线性判别分析

- 线性回归是指使用一条线，尽量拟合所有的数据点，也就是形成
    >y = w*x + b

    对w和b进行求解，即找到这么一条曲线。

- 对于分类任务，可以将线性回归得到的y_i输入到sigmoid函数中，根据输出的0or1完成分类。

- 对于多分类任务，可以有以下三种方式：

    假设有m个样本，N个类别

    方式 | 训练 | 测试 |
    ---| ---| ---|
    One vs One | 将N个类别两两配对，产生N（N-1）/2个分类任务 | 新样本同时给所有分类器进行投票
    One vs Rest | 某一类作为正例，其他的类作为反例 | 若仅有一个分类器预测为正，那么就是这类；如果多个预测为正，那么根据置信度考虑
    Many vs Many | 若干个类作为正例，若干个类作为反例 | **没说**

- 对于类别不平衡的问题，有以下方法

    方法 | 解释
    ---| ---|
    欠采样 | 去除数量多的那个类使数据平衡
    过采样 | 增加数量少的类的样本数
    阈值移动 | 有点复杂，见西瓜书P67，公式3.48
    